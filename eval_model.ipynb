{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "from detection.datasets import coco, data_generator\n",
    "from detection.models.detectors import faster_rcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.82s)\n",
      "creating index...\n",
      "index created!\n",
      "4952\n"
     ]
    }
   ],
   "source": [
    "img_mean = (123.675, 116.28, 103.53)\n",
    "# img_std = (58.395, 57.12, 57.375)\n",
    "img_std = (1., 1., 1.)\n",
    "\n",
    "val_dataset = coco.CocoDataSet('/workspace/shared_workspace/data/coco/', 'val',\n",
    "                               flip_ratio=0,\n",
    "                               pad_mode='fixed',\n",
    "                               mean=img_mean,\n",
    "                               std=img_std,\n",
    "                               scale=(800, 1216))\n",
    "print(len(val_dataset))\n",
    "\n",
    "\n",
    "model = faster_rcnn.FasterRCNN(\n",
    "    num_classes=len(val_dataset.get_categories()))\n",
    "\n",
    "\n",
    "img, img_meta, bboxes, labels = val_dataset[0]\n",
    "batch_imgs = tf.Variable(np.expand_dims(img, 0))\n",
    "batch_metas = tf.Variable(np.expand_dims(img_meta, 0))\n",
    "model.layers[0].trainable=False\n",
    "_ = model((batch_imgs, batch_metas), training=False)\n",
    "for layer in model.layers[0].layers[0].layers[80:]:\n",
    "    if type(layer)!=BatchNormalization:\n",
    "        layer.trainable=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "for layer in model.layers[0].layers[0].layers[80:]:\n",
    "    if type(layer)!=BatchNormalization:\n",
    "        layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/workspace/shared_workspace/tf-eager-fasterrcnn/rcnn_keras_resnet_50_stage_4.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, img_meta, _, _ = val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals = model.simple_test_rpn(img, img_meta)\n",
    "res = model.simple_test_bboxes(img, img_meta, proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rois': array([[ 41.82089 ,  61.422504, 117.689   , 103.92925 ],\n",
       "        [170.83339 , 246.84862 , 233.08075 , 318.86612 ],\n",
       "        [190.4907  , 270.03955 , 230.30336 , 312.7552  ],\n",
       "        [371.7068  , 287.89755 , 389.42313 , 296.51343 ],\n",
       "        [180.25293 , 281.556   , 224.87338 , 310.39014 ],\n",
       "        [160.63518 , 241.84042 , 211.91447 , 299.6857  ]], dtype=float32),\n",
       " 'class_ids': array([34, 10, 10,  1, 10, 10], dtype=int32),\n",
       " 'scores': array([0.9927739 , 0.91881365, 0.8723484 , 0.85960287, 0.707494  ,\n",
       "        0.33169097], dtype=float32)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.backbone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "\n",
    "dataset_results = []\n",
    "imgIds = []\n",
    "for idx in range(100):\n",
    "    if idx % 100 == 0:\n",
    "        print(idx)\n",
    "\n",
    "    img, img_meta, _, _ = val_dataset[idx]\n",
    "\n",
    "    proposals = model.simple_test_rpn(img, img_meta)\n",
    "    res = model.simple_test_bboxes(img, img_meta, proposals)\n",
    "    \n",
    "    image_id = val_dataset.img_ids[idx]\n",
    "    imgIds.append(image_id)\n",
    "    \n",
    "    for pos in range(res['class_ids'].shape[0]):\n",
    "        results = dict()\n",
    "        results['score'] = float(res['scores'][pos])\n",
    "        results['category_id'] = int(res['class_ids'][pos])\n",
    "        y1, x1, y2, x2 = [float(num) for num in list(res['rois'][pos])]\n",
    "        results['bbox'] = [x1, y1, x2 - x1 + 1, y2 - y1 + 1]\n",
    "        results['image_id'] = image_id\n",
    "        dataset_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coco_val2017_detection_result.json', 'w') as f:\n",
    "    f.write(json.dumps(dataset_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_dt = val_dataset.coco.loadRes('coco_val2017_detection_result.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoEval = COCOeval(val_dataset.coco, coco_dt, 'bbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoEval.params.imgIds = imgIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.15s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007\n"
     ]
    }
   ],
   "source": [
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
