{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "from detection.datasets import coco, data_generator\n",
    "from detection.models.detectors import faster_rcnn\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.54s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "img_mean = (123.675, 116.28, 103.53)\n",
    "# img_std = (58.395, 57.12, 57.375)\n",
    "img_std = (1., 1., 1.)\n",
    "batch_size = 8\n",
    "val_dataset = coco.CocoDataSet('/workspace/shared_workspace/data/coco/', 'val',\n",
    "                               flip_ratio=0,\n",
    "                               pad_mode='fixed',\n",
    "                               mean=img_mean,\n",
    "                               std=img_std,\n",
    "                               scale=(800, 1216))\n",
    "\n",
    "val_generator = data_generator.DataGenerator(val_dataset, shuffle=True)\n",
    "val_tf_dataset = tf.data.Dataset.from_generator(\n",
    "    val_generator, (tf.float32, tf.float32, tf.float32, tf.int32, tf.int32))\n",
    "\n",
    "val_tf_dataset = val_tf_dataset.prefetch(16) #.shuffle(100).shard(hvd.size(), hvd.rank())\n",
    "'''val_tf_dataset = val_tf_dataset.padded_batch(\n",
    "                            batch_size,\n",
    "                            padded_shapes=(\n",
    "                            tf.TensorShape([None, None, 3]), # image padded to largest in batch\n",
    "                            tf.TensorShape([11]),            # image meta - no padding\n",
    "                            tf.TensorShape([None, 4]),       # bounding boxes, padded to longest\n",
    "                            tf.TensorShape([None]),           # labels, padded to longest\n",
    "                            tf.TensorShape([None])),\n",
    "                            padding_values=(0.0, 0.0, 0.0, -1, -1))'''\n",
    "\n",
    "# flip channel order\n",
    "def flip_channels(img, img_meta, bbox, label, labels):\n",
    "    img = tf.reverse(img, axis=[-1])\n",
    "    return img, img_meta, bbox, label\n",
    "\n",
    "val_tf_dataset = val_tf_dataset.filter(lambda w, x, y, z, a: tf.equal(tf.shape(w)[0], batch_size))\n",
    "val_tf_dataset = val_tf_dataset.map(flip_channels, num_parallel_calls=16)\n",
    "val_tf_dataset = iter(val_tf_dataset.repeat())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tf_dataset = tf.data.Dataset.from_generator(\n",
    "    val_generator, (tf.float32, tf.float32, tf.float32, tf.int32, tf.int32))\n",
    "val_tf_dataset = val_tf_dataset.prefetch(16)\n",
    "val_tf_dataset = val_tf_dataset.padded_batch(\n",
    "                            batch_size,\n",
    "                            padded_shapes=(\n",
    "                            tf.TensorShape([None, None, 3]), # image padded to largest in batch\n",
    "                            tf.TensorShape([11]),            # image meta - no padding\n",
    "                            tf.TensorShape([None, 4]),       # bounding boxes, padded to longest\n",
    "                            tf.TensorShape([None]),           # labels, padded to longest\n",
    "                            tf.TensorShape([None])),\n",
    "                            padding_values=(0.0, 0.0, 0.0, -1, -1))\n",
    "def flip_channels(img, img_meta, bbox, label, labels):\n",
    "    img = tf.reverse(img, axis=[-1])\n",
    "    return img, img_meta, bbox, label, labels\n",
    "\n",
    "val_tf_dataset = val_tf_dataset.filter(lambda w, x, y, z, a: tf.equal(tf.shape(w)[0], batch_size))\n",
    "val_tf_dataset = val_tf_dataset.map(flip_channels, num_parallel_calls=16)\n",
    "val_tf_dataset = iter(val_tf_dataset.repeat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def evaluate_tf_function(imgs, img_metas):\n",
    "    c2, c3, c4, c5 = model.backbone(imgs, training=False)\n",
    "    p2, p3, p4, p5, p6 = model.neck((c2, c3, c4, c5), training=False)\n",
    "    rpn_class_logits, rpn_probs, rpn_deltas = model.rpn_head((p2, p3, p4, p5, p6), training=False)\n",
    "    proposals = model.rpn_head.get_proposals(rpn_probs, rpn_deltas, img_metas)\n",
    "    pooled_regions = model.roi_align((proposals, (p2, p3, p4, p5), img_metas), training=False)\n",
    "    cnn_class_logits, rcnn_probs, rcnn_deltas = \\\n",
    "                model.bbox_head(pooled_regions, training=False)\n",
    "    detections_list = model.bbox_head.get_bboxes(\n",
    "                    rcnn_probs, rcnn_deltas, proposals, img_metas)\n",
    "    return detections_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = faster_rcnn.FasterRCNN(\n",
    "    num_classes=len(val_dataset.get_categories()), batch_size=batch_size)\n",
    "\n",
    "imgs, img_metas, bboxes, labels, ids = next(val_tf_dataset)\n",
    "\n",
    "_ = model((imgs, img_metas, bboxes, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable=False\n",
    "\n",
    "for layer in model.layers[0].layers[0].layers[142:]:\n",
    "    if type(layer)!=BatchNormalization:\n",
    "        layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights( \\\n",
    "'/workspace/shared_workspace/rcnn_keras_resnet_50_stage_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483b522cba8a4a4780a5b1ba97901822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "detections_list = []\n",
    "img_ids = []\n",
    "metas = []\n",
    "for i in tqdm(range(100)):\n",
    "    imgs, img_metas, bboxes, labels, ids = next(val_tf_dataset)\n",
    "    detections_list.append(evaluate_tf_function(imgs, img_metas))\n",
    "    img_ids.append(ids)\n",
    "    metas.append(img_metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detections_single(detection, img_id, meta):\n",
    "    detection = tf.gather_nd(detection, tf.where(tf.reduce_mean(detection, axis=1)))\n",
    "    boxes = detection[...,:4].numpy()\n",
    "    labels = detection[...,4].numpy()\n",
    "    probs = detection[...,5].numpy()\n",
    "    boxes = boxes[...,[1, 0, 3, 2]]/meta[-2].numpy()\n",
    "    boxes[..., 2] = boxes[..., 2] - boxes[..., 0] \n",
    "    boxes[..., 3] = boxes[..., 3] - boxes[..., 1] \n",
    "    json_list = []\n",
    "    for box, label, score in zip(boxes, labels, probs):\n",
    "        json_list.append({\"image_id\": int(img_id.numpy()[0]), \"category_id\": int(label), \"bbox\": box.tolist(), \"score\": float(score)})\n",
    "    return json_list\n",
    "\n",
    "def get_detection_batch(detections_batch, img_id_batch, meta_batch):\n",
    "    json_list = []\n",
    "    for detection, img_id, meta in zip(detections_batch, img_id_batch, meta_batch):\n",
    "        json_list.extend(get_detections_single(detection, img_id, meta))\n",
    "    return json_list\n",
    "\n",
    "def get_detections(detections_list, img_ids, metas):\n",
    "    json_list = []\n",
    "    for detections_batch, img_id_batch, meta_batch in zip(detections_list, img_ids, metas):\n",
    "        json_list.extend(get_detection_batch(detections_batch, img_id_batch, meta_batch))\n",
    "    return json_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = get_detections(detections_list, img_ids, metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('eval_pred.json', 'w') as outfile:\n",
    "    outfile.write(json.dumps(json_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "cocoDt = val_dataset.coco.loadRes('eval_pred.json')\n",
    "cocoEval = COCOeval(val_dataset.coco,cocoDt,'bbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoEval.params.imgIds = tf.reshape(tf.concat(img_ids, axis=0), [-1]).numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.75s).\n"
     ]
    }
   ],
   "source": [
    "cocoEval.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating evaluation results...\n",
      "DONE (t=0.44s).\n"
     ]
    }
   ],
   "source": [
    "cocoEval.accumulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n"
     ]
    }
   ],
   "source": [
    "cocoEval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path('eval_pred.json').unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "from detection.datasets import coco, data_generator\n",
    "from detection.models.detectors import faster_rcnn\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class Evaluator(object):\n",
    "    \n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.val_tf_dataset = self.get_eval_data()\n",
    "        \n",
    "    def get_eval_data(self):\n",
    "        mg_mean = (123.675, 116.28, 103.53)\n",
    "        # img_std = (58.395, 57.12, 57.375)\n",
    "        img_std = (1., 1., 1.)\n",
    "        batch_size = 8\n",
    "        val_dataset = coco.CocoDataSet('/workspace/shared_workspace/data/coco/', 'val',\n",
    "                                       flip_ratio=0,\n",
    "                                       pad_mode='fixed',\n",
    "                                       mean=img_mean,\n",
    "                                       std=img_std,\n",
    "                                       scale=(800, 1216))\n",
    "\n",
    "        val_generator = data_generator.DataGenerator(val_dataset, shuffle=True)        \n",
    "        val_tf_dataset = tf.data.Dataset.from_generator(\n",
    "            val_generator, (tf.float32, tf.float32, tf.float32, tf.int32, tf.int32))\n",
    "        val_tf_dataset = val_tf_dataset.prefetch(16)\n",
    "        val_tf_dataset = val_tf_dataset.padded_batch(\n",
    "                                    batch_size,\n",
    "                                    padded_shapes=(\n",
    "                                    tf.TensorShape([None, None, 3]), # image padded to largest in batch\n",
    "                                    tf.TensorShape([11]),            # image meta - no padding\n",
    "                                    tf.TensorShape([None, 4]),       # bounding boxes, padded to longest\n",
    "                                    tf.TensorShape([None]),           # labels, padded to longest\n",
    "                                    tf.TensorShape([None])),\n",
    "                                    padding_values=(0.0, 0.0, 0.0, -1, -1))\n",
    "        def flip_channels(img, img_meta, bbox, label, labels):\n",
    "            img = tf.reverse(img, axis=[-1])\n",
    "            return img, img_meta, bbox, label, labels\n",
    "\n",
    "        val_tf_dataset = val_tf_dataset.filter(lambda w, x, y, z, a: tf.equal(tf.shape(w)[0], batch_size))\n",
    "        val_tf_dataset = val_tf_dataset.map(flip_channels, num_parallel_calls=16)\n",
    "        val_tf_dataset = iter(val_tf_dataset.repeat())\n",
    "        return val_tf_dataset\n",
    "    \n",
    "def get_detections_single(detection, img_id, meta):\n",
    "    detection = tf.gather_nd(detection, tf.where(tf.reduce_mean(detection, axis=1)))\n",
    "    boxes = detection[...,:4].numpy()\n",
    "    labels = detection[...,4].numpy()\n",
    "    probs = detection[...,5].numpy()\n",
    "    boxes = boxes[...,[1, 0, 3, 2]]/meta[-2].numpy()\n",
    "    boxes[..., 2] = boxes[..., 2] - boxes[..., 0] \n",
    "    boxes[..., 3] = boxes[..., 3] - boxes[..., 1] \n",
    "    json_list = []\n",
    "    for box, label, score in zip(boxes, labels, probs):\n",
    "        json_list.append({\"image_id\": int(img_id.numpy()[0]), \"category_id\": int(label), \"bbox\": box.tolist(), \"score\": float(score)})\n",
    "    return json_list\n",
    "\n",
    "def get_detection_batch(detections_batch, img_id_batch, meta_batch):\n",
    "    json_list = []\n",
    "    for detection, img_id, meta in zip(detections_batch, img_id_batch, meta_batch):\n",
    "        json_list.extend(get_detections_single(detection, img_id, meta))\n",
    "    return json_list\n",
    "\n",
    "def get_detections(detections_list, img_ids, metas):\n",
    "    json_list = []\n",
    "    for detections_batch, img_id_batch, meta_batch in zip(detections_list, img_ids, metas):\n",
    "        json_list.extend(get_detection_batch(detections_batch, img_id_batch, meta_batch))\n",
    "    return json_list\n",
    "    \n",
    "    def evaluate(detections, img_ids, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
